# 정규화 점검 결과 평가 및 개선 방안 (수정본)

## 📊 점검 결과 요약

### ✅ 정상 동작
- **데이터 정규화**: ImageDataset에서 `/255.0`으로 [0,1] 범위 정규화 정상
- **모델 출력 범위**: `torch.clamp(out, 0.0, 1.0)`으로 [0,1] 범위 보장
- **샘플 3**: 출력과 GT의 밝기가 비슷함 (평균 차이 < 0.1)
- **Activation 선택**: `clamp`가 `sigmoid`보다 나은 선택임 (sigmoid 사용 시 모든 샘플이 밝게 나옴)

### ⚠️ 발견된 문제점

#### 1. **출력 밝기 편향 문제** (샘플 1, 2)
- **증상**: 
  - 출력 평균이 GT 평균보다 **0.23 이상 높음**
  - 출력의 **33.8%**가 0.8~1.0 구간에 몰려있음 (GT는 4.7%)
  - 출력이 과도하게 밝게 생성됨

- **중요한 관찰**:
  - ❌ **Sigmoid 사용 시**: 모든 샘플이 밝게 나옴 → 더 나쁨
  - ⚠️ **Clamp 사용 시**: 일부 샘플(1,2)은 밝지만, 샘플 3은 정상 → 부분적 개선
  - **결론**: Activation 함수가 근본 원인은 아님!

- **진짜 원인 분석**:
  1. **Loss 함수의 한계**: 
     - L1 + SSIM Loss가 밝은 값에 대한 충분한 패널티를 주지 못함
     - 특히 밝은 영역에서의 오차가 상대적으로 작게 계산될 수 있음
  
  2. **데이터셋 불균형**:
     - 샘플 3은 정상, 샘플 1,2는 문제 → 특정 타입의 이미지에 대한 학습 부족
     - 밝은 이미지와 어두운 이미지의 비율 불균형 가능성
  
  3. **학습 과정의 편향**:
     - 모델이 밝은 값으로 학습되는 경향이 있음
     - Loss가 밝은 값에 대해 관대할 수 있음

## 🔧 개선 방안 (수정)

### ❌ **1. Activation 함수 변경은 권장하지 않음**
**이유**: 
- Sigmoid 사용 시 모든 샘플이 밝게 나옴 (더 나쁨)
- Clamp가 현재로서는 더 나은 선택
- Activation 함수 변경은 문제를 해결하지 못함

### ✅ **1. Loss 함수 개선** (우선순위: 높음) ⭐
**현재**: `CombinedLoss(l1_weight=1.0, ssim_weight=1.0)`

**개선 옵션**:
- **옵션 A**: L1 가중치 증가 (밝기 차이에 더 민감하게)
  ```python
  criterion = CombinedLoss(l1_weight=2.0, ssim_weight=1.0)
  # 또는
  criterion = CombinedLoss(l1_weight=3.0, ssim_weight=1.0)
  ```

- **옵션 B**: MSE Loss 추가 (밝은 값의 오차에 더 큰 패널티)
  ```python
  class CombinedLoss(nn.Module):
      def __init__(self, l1_weight=1.0, ssim_weight=1.0, mse_weight=0.5):
          self.l1_loss = nn.L1Loss()
          self.mse_loss = nn.MSELoss()  # 추가
          self.ssim_loss = SSIMLoss()
          ...
      def forward(self, pred, target):
          l1 = self.l1_loss(pred, target)
          mse = self.mse_loss(pred, target)  # 밝은 값의 오차에 제곱 패널티
          ssim = self.ssim_loss(pred, target)
          return self.l1_weight * l1 + self.mse_weight * mse + self.ssim_weight * ssim
  ```

- **옵션 C**: Histogram Loss 추가
  - 출력과 GT의 픽셀 분포 차이를 직접 최소화
  - 밝기 분포 불일치에 직접적으로 패널티 부여

### ✅ **2. 데이터셋 검증 및 불균형 해소** (우선순위: 높음) ⭐
- **문제**: 일부 샘플은 정상, 일부는 문제 → 데이터 불균형 가능성
- **조치**:
  1. 학습 데이터의 밝기 분포 확인
     ```python
     # 학습 데이터의 평균 밝기 분포 확인
     # 밝은 이미지(평균 > 0.6) vs 어두운 이미지(평균 < 0.4) 비율
     ```
  2. 밝은 이미지와 어두운 이미지의 비율 확인
  3. 필요시 데이터 증강으로 균형 조정
     - 밝기 조정 augmentation 추가
     - 밝은 이미지에 대한 가중치 증가

### ✅ **3. 학습 하이퍼파라미터 조정** (우선순위: 중간)
- **Learning rate 감소**: 더 세밀한 학습 (예: 1e-4 → 5e-5)
- **학습 에포크 증가**: 충분한 학습 기회 제공
- **Learning rate scheduler 사용**: CosineAnnealing 등으로 안정적 학습
- **Batch size 조정**: 더 안정적인 gradient 추정

### ✅ **4. 추가 Loss 항목** (우선순위: 중간)
- **Perceptual Loss**: VGG 기반으로 구조적 유사성 학습
- **Brightness Loss**: 평균 밝기 차이에 직접 패널티
  ```python
  brightness_loss = torch.abs(pred.mean() - target.mean())
  ```

## 📈 예상 효과

### Loss 함수 개선 후 예상 결과:
- ✅ 밝은 값에 대한 패널티 증가
- ✅ 출력 평균이 GT 평균에 더 가까워짐
- ✅ 0.8~1.0 구간에 몰리는 현상 감소

### 데이터셋 균형 조정 후 예상 결과:
- ✅ 다양한 밝기의 이미지에 대해 균형잡힌 학습
- ✅ 샘플 간 일관성 향상

## 🎯 권장 실행 순서 (수정)

1. **1단계**: Loss 함수 개선 ⭐
   - L1 가중치를 2.0~3.0으로 증가
   - 또는 MSE Loss 추가
   - 기존 체크포인트에서 fine-tuning 가능

2. **2단계**: 데이터셋 검증
   - 학습 데이터의 밝기 분포 확인
   - 불균형 발견 시 데이터 증강 또는 샘플링 전략 변경

3. **3단계**: 재학습 후 정규화 점검 재실행
   - 히스토그램 분석으로 개선 여부 확인
   - 모든 샘플에서 일관된 결과 확인

4. **4단계**: 여전히 문제가 있으면 추가 Loss 항목 고려
   - Histogram Loss 또는 Brightness Loss 추가

## 📝 추가 확인 사항

1. **학습 로그 확인**:
   - Train Loss vs Val Loss 추이
   - PSNR, SSIM 메트릭 추이
   - 과적합 여부 확인
   - **샘플별 Loss 분포 확인** (어떤 샘플에서 Loss가 높은지)

2. **모델 체크포인트 확인**:
   - 어떤 체크포인트를 사용했는지 확인
   - Best model인지, 마지막 epoch인지 확인
   - **샘플 1,2와 샘플 3의 학습 데이터 비율 확인**

3. **추가 샘플 테스트**:
   - 현재 3개 샘플만 테스트 → 더 많은 샘플로 검증 필요
   - 전체 테스트셋에 대한 통계 확인
   - **밝은 이미지 vs 어두운 이미지 비율 확인**

## ✅ 결론 (수정)

**핵심 문제**: 
- ❌ Activation 함수가 문제가 아님 (sigmoid는 더 나쁨, clamp가 더 나음)
- ✅ **Loss 함수가 밝은 값에 대한 충분한 패널티를 주지 못함**
- ✅ **데이터셋 불균형 가능성** (일부 샘플만 문제)

**즉시 조치**: 
1. **Loss 함수 개선** (L1 가중치 증가 또는 MSE 추가)
2. **데이터셋 검증** (밝기 분포 확인)

**장기 개선**: 
- Histogram Loss 추가
- 데이터 증강으로 균형 조정
- 학습 하이퍼파라미터 최적화



## 핵심 요약

1. Sigmoid는 더 나쁨: 모든 샘플이 밝게 나옴
2. Clamp가 더 나음: 샘플 3은 정상, 일부만 문제
3. 진짜 원인:
   - Loss 함수가 밝은 값에 대한 패널티가 부족
   - 데이터셋 불균형 가능성

## 권장 조치

1. Loss 함수 개선 (최우선)
   - L1 가중치를 2.0~3.0으로 증가
   - 또는 MSE Loss 추가

2. 데이터셋 검증
   - 학습 데이터의 밝기 분포 확인
   - 샘플 1,2와 샘플 3의 특성 차이 확인

Activation 함수는 그대로 두고, Loss 함수와 데이터셋을 먼저 확인하세요.