import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from PIL import Image
import os
from pathlib import Path
import cv2
from skimage.metrics import structural_similarity as ssim
from skimage.metrics import peak_signal_noise_ratio as psnr
import matplotlib.pyplot as plt


class CNNModel(nn.Module):
    """
    4-layer CNN ëª¨ë¸ for ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°
    Conv-BN-ReLU ë¸”ë¡ êµ¬ì¡°
    ì±„ë„ ìˆ˜: 64 -> 128 -> 256 -> 512
    Residual Learning ì ìš©: ëª¨ë¸ì´ ë…¸ì´ì¦ˆë§Œ ì˜ˆì¸¡í•˜ê³  ì…ë ¥ì—ì„œ ë¹¼ì„œ clean ì´ë¯¸ì§€ ìƒì„±
    """
    def __init__(self, in_channels=3, out_channels=3, use_residual=True):
        super(CNNModel, self).__init__()
        self.use_residual = use_residual
        
        # Layer 1: 64 channels
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        
        # Layer 2: 128 channels
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        
        # Layer 3: 256 channels
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm2d(256)
        
        # Layer 4: 512 channels
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
        self.bn4 = nn.BatchNorm2d(512)
        
        # Decoder: 512 -> 256 -> 128 -> 64 -> 3
        self.conv5 = nn.Conv2d(512, 256, kernel_size=3, padding=1)
        self.bn5 = nn.BatchNorm2d(256)
        
        self.conv6 = nn.Conv2d(256, 128, kernel_size=3, padding=1)
        self.bn6 = nn.BatchNorm2d(128)
        
        self.conv7 = nn.Conv2d(128, 64, kernel_size=3, padding=1)
        self.bn7 = nn.BatchNorm2d(64)
        
        self.conv8 = nn.Conv2d(64, out_channels, kernel_size=3, padding=1)
        
    def forward(self, x):
        # Encoder path
        x1 = F.relu(self.bn1(self.conv1(x)))
        x2 = F.relu(self.bn2(self.conv2(x1)))
        x3 = F.relu(self.bn3(self.conv3(x2)))
        x4 = F.relu(self.bn4(self.conv4(x3)))
        
        # Decoder path
        x5 = F.relu(self.bn5(self.conv5(x4)))
        x6 = F.relu(self.bn6(self.conv6(x5)))
        x7 = F.relu(self.bn7(self.conv7(x6)))
        residual = self.conv8(x7)
        
        # Residual Learning: ëª¨ë¸ì´ ë…¸ì´ì¦ˆë§Œ ì˜ˆì¸¡í•˜ê³  ì…ë ¥ì—ì„œ ë¹¼ì„œ clean ì´ë¯¸ì§€ ìƒì„±
        if self.use_residual:
            # residualì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™” (tanh ì‚¬ìš©)
            residual = torch.tanh(residual)
            # ì…ë ¥ì—ì„œ ë…¸ì´ì¦ˆë¥¼ ë¹¼ì„œ clean ì´ë¯¸ì§€ ìƒì„±
            out = x - residual
            # [0, 1] ë²”ìœ„ë¡œ í´ë¦¬í•‘
            out = torch.clamp(out, 0.0, 1.0)
        else:
            # ê¸°ì¡´ ë°©ì‹: ì „ì²´ ì´ë¯¸ì§€ ì˜ˆì¸¡
            out = torch.sigmoid(residual)
        
        return out


class SSIMLoss(nn.Module):
    """
    SSIM Loss êµ¬í˜„
    """
    def __init__(self, window_size=11, size_average=True):
        super(SSIMLoss, self).__init__()
        self.window_size = window_size
        self.size_average = size_average
        self.channel = 1
        self.window = self.create_window(window_size, self.channel)

    def gaussian(self, window_size, sigma):
        gauss = torch.Tensor([np.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])
        return gauss/gauss.sum()

    def create_window(self, window_size, channel):
        _1D_window = self.gaussian(window_size, 1.5).unsqueeze(1)
        _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)
        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()
        return window

    def _ssim(self, img1, img2, window, window_size, channel, size_average=True):
        mu1 = F.conv2d(img1, window, padding=window_size//2, groups=channel)
        mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)

        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1*mu2

        sigma1_sq = F.conv2d(img1*img1, window, padding=window_size//2, groups=channel) - mu1_sq
        sigma2_sq = F.conv2d(img2*img2, window, padding=window_size//2, groups=channel) - mu2_sq
        sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) - mu1_mu2

        C1 = 0.01**2
        C2 = 0.03**2

        ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))

        if size_average:
            return ssim_map.mean()
        else:
            return ssim_map.mean(1).mean(1).mean(1)

    def forward(self, img1, img2):
        (_, channel, _, _) = img1.size()

        if channel == self.channel and self.window.data.type() == img1.data.type():
            window = self.window
        else:
            window = self.create_window(self.window_size, channel)
            
            if img1.is_cuda:
                window = window.cuda(img1.get_device())
            window = window.type_as(img1)
            
            self.window = window
            self.channel = channel

        return 1 - self._ssim(img1, img2, window, self.window_size, channel, self.size_average)


class CombinedLoss(nn.Module):
    """
    L1 Loss + SSIM Loss + Gradient Loss ì¡°í•©
    Gradient LossëŠ” ë…¸ì´ì¦ˆ ì œê±°ì— ì§‘ì¤‘ (ë…¸ì´ì¦ˆëŠ” ê³ ì£¼íŒŒ ì„±ë¶„)
    """
    def __init__(self, l1_weight=1.0, ssim_weight=1.0, gradient_weight=0.5):
        super(CombinedLoss, self).__init__()
        self.l1_loss = nn.L1Loss()
        self.ssim_loss = SSIMLoss()
        self.l1_weight = l1_weight
        self.ssim_weight = ssim_weight
        self.gradient_weight = gradient_weight
        
    def gradient_loss(self, pred, target):
        """
        Gradient Loss: ì´ë¯¸ì§€ì˜ gradient(ì—£ì§€/ê²½ê³„) ì°¨ì´ë¥¼ ì¸¡ì •
        ë…¸ì´ì¦ˆëŠ” ê³ ì£¼íŒŒ ì„±ë¶„ì´ë¯€ë¡œ gradientê°€ í¬ê³ , ì´ë¥¼ ì¤„ì´ë„ë¡ í•™ìŠµ
        """
        # Sobel í•„í„° ì •ì˜
        sobel_x = torch.tensor([[-1, 0, 1], 
                                [-2, 0, 2], 
                                [-1, 0, 1]], dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)
        sobel_y = torch.tensor([[-1, -2, -1], 
                                [0, 0, 0], 
                                [1, 2, 1]], dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)
        
        # ê° ì±„ë„ì— ëŒ€í•´ gradient ê³„ì‚°
        # RGB ì±„ë„ì´ë¯€ë¡œ 3ë²ˆ ë°˜ë³µ
        sobel_x = sobel_x.repeat(pred.shape[1], 1, 1, 1)
        sobel_y = sobel_y.repeat(pred.shape[1], 1, 1, 1)
        
        pred_grad_x = F.conv2d(pred, sobel_x, padding=1, groups=pred.shape[1])
        pred_grad_y = F.conv2d(pred, sobel_y, padding=1, groups=pred.shape[1])
        target_grad_x = F.conv2d(target, sobel_x, padding=1, groups=target.shape[1])
        target_grad_y = F.conv2d(target, sobel_y, padding=1, groups=target.shape[1])
        
        # Gradient magnitude (í¬ê¸°)
        pred_grad = torch.sqrt(pred_grad_x**2 + pred_grad_y**2 + 1e-6)
        target_grad = torch.sqrt(target_grad_x**2 + target_grad_y**2 + 1e-6)
        
        # L1 Lossë¡œ gradient ì°¨ì´ ì¸¡ì •
        return F.l1_loss(pred_grad, target_grad)
        
    def forward(self, pred, target):
        l1 = self.l1_loss(pred, target)
        ssim = self.ssim_loss(pred, target)
        grad = self.gradient_loss(pred, target)
        return self.l1_weight * l1 + self.ssim_weight * ssim + self.gradient_weight * grad


class ImageDataset(Dataset):
    """
    ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ì™€ ê¹¨ë—í•œ ì´ë¯¸ì§€ ìŒì„ ë¡œë“œí•˜ëŠ” Dataset
    
    ì‚¬ìš© ë°©ë²•:
    1. ë‘ ê°œì˜ í´ë” ì‚¬ìš©: noisy_dirì™€ clean_dirê°€ ë‹¤ë¥¸ ê²½ìš°
       - ê° í´ë”ì—ì„œ ê°™ì€ íŒŒì¼ëª…ì˜ ì´ë¯¸ì§€ë¥¼ ë§¤ì¹­
    2. í•˜ë‚˜ì˜ í´ë” ì‚¬ìš© (ì •ì œëœ ë°ì´í„°): noisy_dirì™€ clean_dirê°€ ê°™ì€ ê²½ìš°
       - íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ë§¤ì¹­ (*_rain.png <-> *_clean.png)
    3. Inference ì „ìš© ëª¨ë“œ: inference_only=True
       - clean ì´ë¯¸ì§€ ì—†ì´ noisy ì´ë¯¸ì§€ë§Œ ë°˜í™˜ (ì‹œê°ì  í‰ê°€ìš©)
    4. ë§¤ì¹­ íŒŒì¼ ì‚¬ìš©: matched_pairs_fileì´ ì œê³µëœ ê²½ìš°
       - JSON íŒŒì¼ì—ì„œ ë§¤ì¹­ ì •ë³´ë¥¼ ì½ì–´ì˜´ (í´ë”ëª… ê¸°ë°˜ ë§¤ì¹­ ê²°ê³¼)
    """
    def __init__(self, noisy_dir, clean_dir=None, transform=None, 
                 noisy_pattern='*_rain.png', clean_pattern='*_clean.png',
                 inference_only=False, matched_pairs_file=None, auto_match=False, split=None,
                 reverse_match=False):
        # split íŒŒë¼ë¯¸í„° ì¶”ê°€: None(ëª¨ë“  split), 'train', 'val', 'test'
        # reverse_match: Trueë©´ ì›ë³¸ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­, Falseë©´ ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­
        self.noisy_dir = Path(noisy_dir)
        self.transform = transform
        self.inference_only = inference_only
        self.split = split  # split ì •ë³´ ì €ì¥
        
        # ìë™ ë§¤ì¹­ ëª¨ë“œ: í•™ìŠµ ì‹œ ìë™ìœ¼ë¡œ í´ë”ëª… ê¸°ë°˜ ë§¤ì¹­
        if auto_match and clean_dir is not None:
            print("ìë™ ë§¤ì¹­ ëª¨ë“œ: í´ë”ëª… ê¸°ë°˜ìœ¼ë¡œ ìë™ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
            if split:
                print(f"  Split í•„í„°: {split}ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.")
            if reverse_match:
                print(f"  ë§¤ì¹­ ë°©ì‹: ì›ë³¸ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë…¸ì´ì¦ˆ ë°ì´í„° ì°¾ê¸°")
            else:
                print(f"  ë§¤ì¹­ ë°©ì‹: ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ ë°ì´í„° ì°¾ê¸°")
            self.pairs = self._auto_match_by_folder_name(noisy_dir, clean_dir, split=split, reverse_match=reverse_match)
            print(f"ìë™ ë§¤ì¹­ ì™„ë£Œ: {len(self.pairs)}ê°œì˜ ì´ë¯¸ì§€ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ë§¤ì¹­ íŒŒì¼ ëª¨ë“œ: JSON íŒŒì¼ì—ì„œ ë§¤ì¹­ ì •ë³´ ì½ê¸°
        if matched_pairs_file is not None:
            import json
            matched_pairs_path = Path(matched_pairs_file)
            if not matched_pairs_path.exists():
                raise ValueError(f"ë§¤ì¹­ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {matched_pairs_file}")
            
            with open(matched_pairs_path, 'r', encoding='utf-8') as f:
                matched_data = json.load(f)
            
            self.pairs = []
            for pair in matched_data.get('matched_pairs', []):
                noisy_path = Path(pair['noisy_path'])
                clean_path = Path(pair['clean_path'])
                
                # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆë©´ ìƒëŒ€ ê²½ë¡œë¡œ ì²˜ë¦¬
                if not noisy_path.is_absolute():
                    noisy_path = self.noisy_dir / pair.get('noisy_relative', pair['noisy_path'])
                if not clean_path.is_absolute():
                    if clean_dir:
                        clean_path = Path(clean_dir) / pair.get('clean_relative', pair['clean_path'])
                    else:
                        # clean_dirê°€ ì—†ìœ¼ë©´ noisy_dir ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬
                        clean_path = self.noisy_dir / pair.get('clean_relative', pair['clean_path'])
                
                if noisy_path.exists() and clean_path.exists():
                    self.pairs.append((noisy_path, clean_path))
            
            if len(self.pairs) == 0:
                raise ValueError(f"ë§¤ì¹­ íŒŒì¼ì—ì„œ ìœ íš¨í•œ ì´ë¯¸ì§€ ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {matched_pairs_file}")
            
            print(f"ë§¤ì¹­ íŒŒì¼ ëª¨ë“œ: {len(self.pairs)}ê°œì˜ ì´ë¯¸ì§€ ìŒì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            print(f"  ë§¤ì¹­ íŒŒì¼: {matched_pairs_file}")
            return
        
        # Inference ì „ìš© ëª¨ë“œ: clean ì´ë¯¸ì§€ ì—†ì´ noisyë§Œ ë°˜í™˜
        if inference_only:
            self.single_folder_mode = False
            self.noisy_files = sorted(list(self.noisy_dir.glob('**/*.jpg')) + 
                                      list(self.noisy_dir.glob('**/*.png')))
            if len(self.noisy_files) == 0:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.noisy_dir}")
            self.pairs = [(f, None) for f in self.noisy_files]  # cleanì€ None
            print(f"Inference ì „ìš© ëª¨ë“œ: {len(self.pairs)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # clean_dirê°€ Noneì´ê±°ë‚˜ noisy_dirì™€ ê°™ìœ¼ë©´ í•˜ë‚˜ì˜ í´ë”ì—ì„œ íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ë§¤ì¹­
        if clean_dir is None or str(self.noisy_dir) == str(Path(clean_dir)):
            self.single_folder_mode = True
            self.data_dir = self.noisy_dir
            
            # íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ë§¤ì¹­
            noisy_files = sorted(list(self.data_dir.glob(noisy_pattern)))
            # ì›ë³¸ íŒŒì¼ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
            clean_files_dict = {}
            for f in self.data_dir.glob(clean_pattern):
                clean_key = f.stem  # ì›ë³¸ íŒŒì¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
                clean_files_dict[clean_key] = f
            
            # ë§¤ì¹­ë˜ëŠ” ìŒë§Œ ì €ì¥
            self.pairs = []
            for noisy_file in noisy_files:
                # ë…¸ì´ì¦ˆ íŒŒì¼ëª…: aachen_000004_000019_leftImg8bit_rain_alpha_0.02_...
                # _rain ì´í›„ ëª¨ë“  ë¶€ë¶„ ì œê±°
                noisy_stem = noisy_file.stem
                if '_rain' in noisy_stem:
                    base_name = noisy_stem.split('_rain')[0]  # _rain ì´ì „ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                else:
                    base_name = noisy_stem
                
                clean_file = clean_files_dict.get(base_name)
                if clean_file and clean_file.exists():
                    self.pairs.append((noisy_file, clean_file))
            
            if len(self.pairs) == 0:
                raise ValueError(f"ë§¤ì¹­ë˜ëŠ” ì´ë¯¸ì§€ ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                               f"í´ë”: {self.data_dir}, "
                               f"íŒ¨í„´: {noisy_pattern} <-> {clean_pattern}")
            
            print(f"ë‹¨ì¼ í´ë” ëª¨ë“œ: {len(self.pairs)}ê°œì˜ ì´ë¯¸ì§€ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        else:
            # ê¸°ì¡´ ë°©ì‹: ë‘ ê°œì˜ í´ë” ì‚¬ìš©
            self.single_folder_mode = False
            self.clean_dir = Path(clean_dir)
            
            # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì¬ê·€ì ìœ¼ë¡œ ì„œë¸Œë””ë ‰í† ë¦¬ íƒìƒ‰)
            self.noisy_files = sorted(list(self.noisy_dir.glob('**/*.jpg')) + 
                                      list(self.noisy_dir.glob('**/*.png')))
            self.clean_files = sorted(list(self.clean_dir.glob('**/*.jpg')) + 
                                      list(self.clean_dir.glob('**/*.png')))
            
            # íŒŒì¼ëª… ê¸°ë°˜ ë§¤ì¹­ (í™•ì¥ì ì œì™¸)
            # ì„œë¸Œë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ê³ ë ¤í•˜ì—¬ ìƒëŒ€ ê²½ë¡œë¡œ ë§¤ì¹­
            # _rain, _clean ë“±ì˜ ì ‘ë¯¸ì‚¬ ì œê±°í•˜ì—¬ ë§¤ì¹­
            noisy_dict = {}
            for f in self.noisy_files:
                # ìƒëŒ€ ê²½ë¡œë¥¼ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ê°™ì€ íŒŒì¼ëª…ì´ ì—¬ëŸ¬ í´ë”ì— ìˆì–´ë„ êµ¬ë¶„
                rel_path = f.relative_to(self.noisy_dir)
                stem = rel_path.stem
                # _rain, _noisy ë“±ì˜ ì ‘ë¯¸ì‚¬ ì œê±°
                # ë…¸ì´ì¦ˆ íŒŒì¼ëª…: aachen_000004_000019_leftImg8bit_rain_alpha_0.02_...
                if '_rain' in stem:
                    base_name = stem.split('_rain')[0]  # '_rain' ì´ì „ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                elif stem.endswith('_noisy'):
                    base_name = stem[:-6]  # '_noisy' ì œê±°
                else:
                    base_name = stem
                
                key = str(rel_path.parent / base_name) if rel_path.parent != Path('.') else base_name
                noisy_dict[key] = f
            
            clean_dict = {}
            for f in self.clean_files:
                rel_path = f.relative_to(self.clean_dir)
                stem = rel_path.stem
                # _clean, _gt ë“±ì˜ ì ‘ë¯¸ì‚¬ ì œê±°
                if stem.endswith('_clean'):
                    base_name = stem[:-6]  # '_clean' ì œê±°
                elif stem.endswith('_gt'):
                    base_name = stem[:-3]  # '_gt' ì œê±°
                else:
                    base_name = stem
                
                key = str(rel_path.parent / base_name) if rel_path.parent != Path('.') else base_name
                clean_dict[key] = f
            
            # ë§¤ì¹­ë˜ëŠ” ìŒë§Œ ì €ì¥
            self.pairs = []
            for stem in noisy_dict.keys():
                if stem in clean_dict:
                    self.pairs.append((noisy_dict[stem], clean_dict[stem]))
            
            if len(self.pairs) == 0:
                # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
                print(f"ë””ë²„ê¹… ì •ë³´:")
                print(f"  Noisy íŒŒì¼ ìˆ˜: {len(noisy_dict)}")
                print(f"  Clean íŒŒì¼ ìˆ˜: {len(clean_dict)}")
                print(f"  Noisy í‚¤ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ): {list(noisy_dict.keys())[:5]}")
                print(f"  Clean í‚¤ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ): {list(clean_dict.keys())[:5]}")
                raise ValueError("ë§¤ì¹­ë˜ëŠ” ì´ë¯¸ì§€ ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                               f"noisy_dir: {self.noisy_dir}, clean_dir: {self.clean_dir}")
            
            # ë§¤ì¹­ëœ ì„œë¸Œë””ë ‰í† ë¦¬ ì •ë³´ ì¶œë ¥
            matched_subdirs = set()
            for noisy_path, clean_path in self.pairs[:10]:  # ì²˜ìŒ 10ê°œë§Œ í™•ì¸
                noisy_rel = noisy_path.relative_to(self.noisy_dir)
                clean_rel = clean_path.relative_to(self.clean_dir)
                if len(noisy_rel.parts) > 1:
                    matched_subdirs.add(noisy_rel.parts[0])
            
            print(f"ì´ì¤‘ í´ë” ëª¨ë“œ: {len(self.pairs)}ê°œì˜ ì´ë¯¸ì§€ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            if matched_subdirs:
                print(f"  ë§¤ì¹­ëœ ì„œë¸Œë””ë ‰í† ë¦¬ ìƒ˜í”Œ: {sorted(list(matched_subdirs))[:5]}")
    
    def _auto_match_by_folder_name(self, noisy_dir, clean_dir, split=None, reverse_match=False):
        """
        í´ë”ëª… ê¸°ë°˜ ìë™ ë§¤ì¹­ (í•™ìŠµ ì‹œ ìë™ìœ¼ë¡œ í˜¸ì¶œ)
        reverse_match=False: ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ ë°ì´í„° ì°¾ê¸° (ê¸°ë³¸)
        reverse_match=True: ì›ë³¸ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë…¸ì´ì¦ˆ ë°ì´í„° ì°¾ê¸°
        
        ë…¸ì´ì¦ˆ íŒŒì¼ëª…ì—ì„œ ë„ì‹œëª…ì„ ì¶”ì¶œí•˜ì—¬ ì›ë³¸ ë°ì´í„°ì˜ ë„ì‹œ í´ë”ì™€ ë§¤ì¹­
        ì˜ˆ: aachen_000004_000019_leftImg8bit_rain_alpha_0.02_... -> aachen í´ë” ë‚´ íŒŒì¼ë“¤ê³¼ ë§¤ì¹­
        ë…¸ì´ì¦ˆ ë°ì´í„°ì˜ day/night êµ¬ë¶„ ì—†ì´ ëª¨ë‘ í•¨ê»˜ ë§¤ì¹­
        split: Noneì´ë©´ ëª¨ë“  split, 'train', 'val', 'test' ì¤‘ í•˜ë‚˜ë©´ í•´ë‹¹ splitë§Œ
        """
        from collections import defaultdict
        import re
        
        noisy_path = Path(noisy_dir)
        clean_path = Path(clean_dir)
        
        def get_image_files(folder_path):
            """í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
            folder = Path(folder_path)
            if not folder.exists():
                return []
            image_extensions = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}
            image_files = []
            for ext in image_extensions:
                image_files.extend(folder.glob(f'**/*{ext}'))
            return sorted([f for f in image_files])
        
        pairs = []
        # splitì´ ì§€ì •ë˜ë©´ í•´ë‹¹ splitë§Œ, ì•„ë‹ˆë©´ ëª¨ë“  split
        splits = [split] if split else ['test', 'train', 'val']
        
        # noisyê°€ ì´ë¯¸ íŠ¹ì • split í´ë”ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²½ìš° (ì˜ˆ: test í´ë”ë§Œ)
        # cleanì˜ ëª¨ë“  splitì—ì„œ ë§¤ì¹­í•˜ë„ë¡ ì²˜ë¦¬
        noisy_is_split_folder = noisy_path.name in ['test', 'train', 'val']
        if noisy_is_split_folder and split is None:
            # noisyëŠ” ì´ë¯¸ test/train/val ì¤‘ í•˜ë‚˜ë¥¼ ê°€ë¦¬í‚¤ê³  ìˆìŒ
            # cleanì˜ ëª¨ë“  splitì—ì„œ ë§¤ì¹­ ì‹œë„
            actual_noisy_split = noisy_path.name
            print(f"  ë…¸ì´ì¦ˆ ë°ì´í„°ëŠ” {actual_noisy_split} splitë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # noisy íŒŒì¼ì€ í•œ ë²ˆë§Œ ìˆ˜ì§‘
            noisy_files = []
            day_path = noisy_path / 'day'
            night_path = noisy_path / 'night'
            if day_path.exists():
                noisy_files.extend(get_image_files(day_path))
            if night_path.exists():
                noisy_files.extend(get_image_files(night_path))
            
            if len(noisy_files) == 0:
                print(f"  âš ï¸  ë…¸ì´ì¦ˆ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {noisy_path}")
                return []
            
            print(f"  ë…¸ì´ì¦ˆ íŒŒì¼ {len(noisy_files)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # clean í´ë” êµ¬ì¡° í™•ì¸: split êµ¬ì¡°ì¸ì§€, ì§ì ‘ ë„ì‹œ í´ë”ì¸ì§€
            clean_has_split = (clean_path / 'test').exists() or (clean_path / 'train').exists() or (clean_path / 'val').exists()
            
            if clean_has_split:
                # clean í´ë” ì•ˆì— test/train/valì´ ìˆëŠ” ê²½ìš°
                print(f"  clean ë°ì´í„°ëŠ” ëª¨ë“  split (test/train/val)ì—ì„œ ë§¤ì¹­ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                clean_splits = ['test', 'train', 'val']
            else:
                # clean í´ë” ì•ˆì— ë„ì‹œëª… í´ë”ê°€ ì§ì ‘ ìˆëŠ” ê²½ìš°
                print(f"  clean í´ë” ì•ˆì˜ ëª¨ë“  ë„ì‹œ í´ë”ì—ì„œ ë§¤ì¹­ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                clean_splits = [None]  # Noneì€ clean_path ìì²´ë¥¼ ì˜ë¯¸
            
            # cleanì˜ ëª¨ë“  split/í´ë”ì—ì„œ ë§¤ì¹­ ì‹œë„
            for split_name in clean_splits:
                if split_name is None:
                    # clean í´ë” ì§ì ‘ ì‚¬ìš©
                    clean_split_path = clean_path
                else:
                    clean_split_path = clean_path / split_name
                
                if not clean_split_path.exists():
                    continue
                
                # ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘ (ê° í´ë”ë³„ë¡œ)
                clean_folders = {}
                subfolders = [d for d in clean_split_path.iterdir() if d.is_dir()]
                
                if subfolders:
                    for subfolder in subfolders:
                        clean_files = get_image_files(subfolder)
                        if len(clean_files) > 0:
                            clean_folders[subfolder.name] = clean_files
                else:
                    clean_files = get_image_files(clean_split_path)
                    if len(clean_files) > 0:
                        clean_folders['root'] = clean_files
                
                if len(clean_folders) == 0:
                    continue
                
                # ë§¤ì¹­ ë¡œì§
                split_pairs_count = len(pairs)
                if not reverse_match:
                    # ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ ë°ì´í„° ì°¾ê¸°
                    clean_dict = {}
                    for folder_name, clean_files in clean_folders.items():
                        for clean_file in clean_files:
                            clean_stem = clean_file.stem
                            if clean_stem not in clean_dict:
                                clean_dict[clean_stem] = []
                            clean_dict[clean_stem].append(clean_file)
                    
                    # ë…¸ì´ì¦ˆ íŒŒì¼ê³¼ ë§¤ì¹­
                    for noisy_file in noisy_files:
                        noisy_stem = noisy_file.stem
                        if '_rain' in noisy_stem:
                            noisy_key = noisy_stem.split('_rain')[0]
                        else:
                            noisy_key = noisy_stem
                        
                        if noisy_key in clean_dict:
                            # ë§¤ì¹­ëœ clean íŒŒì¼ ì¤‘ ì²« ë²ˆì§¸ ì‚¬ìš©
                            pairs.append((noisy_file, clean_dict[noisy_key][0]))
                else:
                    # ì›ë³¸ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë…¸ì´ì¦ˆ ë°ì´í„° ì°¾ê¸°
                    noisy_dict = {}
                    for noisy_file in noisy_files:
                        noisy_stem = noisy_file.stem
                        if '_rain' in noisy_stem:
                            noisy_key = noisy_stem.split('_rain')[0]
                        else:
                            noisy_key = noisy_stem
                        if noisy_key not in noisy_dict:
                            noisy_dict[noisy_key] = noisy_file
                    
                    for folder_name, clean_files in clean_folders.items():
                        for clean_file in clean_files:
                            clean_stem = clean_file.stem
                            if clean_stem in noisy_dict:
                                pairs.append((noisy_dict[clean_stem], clean_file))
                
                new_pairs = len(pairs) - split_pairs_count
                print(f"  {split_name}: {len(clean_folders)}ê°œ í´ë”, {new_pairs}ê°œ ë§¤ì¹­")
            
            if len(pairs) > 0:
                print(f"  ì´ {len(pairs)}ê°œì˜ ì´ë¯¸ì§€ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            return pairs
        
        # ê¸°ì¡´ ë¡œì§ (ê° splitë³„ë¡œ ë§¤ì¹­)
        for split_name in splits:
            noisy_split_path = noisy_path / split_name
            clean_split_path = clean_path / split_name
            
            if not noisy_split_path.exists() or not clean_split_path.exists():
                if split:  # splitì´ ì§€ì •ë˜ì—ˆëŠ”ë° í´ë”ê°€ ì—†ìœ¼ë©´ ê²½ê³ 
                    print(f"âš ï¸  ê²½ê³ : {split_name} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # ë…¸ì´ì¦ˆ ë°ì´í„° ìˆ˜ì§‘ (day/night êµ¬ë¶„ ì—†ì´ ëª¨ë‘)
            noisy_files = []
            day_path = noisy_split_path / 'day'
            night_path = noisy_split_path / 'night'
            
            if day_path.exists():
                noisy_files.extend(get_image_files(day_path))
            if night_path.exists():
                noisy_files.extend(get_image_files(night_path))
            
            if len(noisy_files) == 0:
                continue
            
            # ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘ (ê° í´ë”ë³„ë¡œ)
            clean_folders = {}
            subfolders = [d for d in clean_split_path.iterdir() if d.is_dir()]
            
            if subfolders:
                for subfolder in subfolders:
                    clean_files = get_image_files(subfolder)
                    if len(clean_files) > 0:
                        clean_folders[subfolder.name] = clean_files
            else:
                clean_files = get_image_files(clean_split_path)
            if len(clean_files) > 0:
                clean_folders['root'] = clean_files
            
            if reverse_match:
                # ì›ë³¸ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë…¸ì´ì¦ˆ ë°ì´í„° ì°¾ê¸°
                noisy_dict = {}  # ë…¸ì´ì¦ˆ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                noisy_dict_multiple = {}  # ê°™ì€ í‚¤ì— ì—¬ëŸ¬ íŒŒì¼ì´ ìˆì„ ìˆ˜ ìˆìŒ
                
                import re  # ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
                
                for noisy_file in noisy_files:
                    noisy_stem = noisy_file.stem
                    # ë…¸ì´ì¦ˆ íŒŒì¼ëª…: aachen_000004_000019_leftImg8bit_rain_alpha_0.02_...
                    # _rain ì´í›„ ëª¨ë“  ë¶€ë¶„ ì œê±°
                    if '_rain' in noisy_stem:
                        noisy_key = noisy_stem.split('_rain')[0]  # aachen_000004_000019_leftImg8bit
                    else:
                        noisy_key = noisy_stem
                    
                    # ê°™ì€ í‚¤ê°€ ì—¬ëŸ¬ ê°œ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
                    if noisy_key not in noisy_dict_multiple:
                        noisy_dict_multiple[noisy_key] = []
                    noisy_dict_multiple[noisy_key].append(noisy_file)
                    # ì²« ë²ˆì§¸ ê²ƒë§Œ ì‚¬ìš© (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
                    if noisy_key not in noisy_dict:
                        noisy_dict[noisy_key] = noisy_file
                
                print(f"  ğŸ” ë…¸ì´ì¦ˆ ë°ì´í„° í‚¤ ê°œìˆ˜: {len(noisy_dict)}ê°œ (ì´ íŒŒì¼: {len(noisy_files)}ê°œ)")
                if len(noisy_dict) < len(noisy_files):
                    print(f"     âš ï¸  ì¤‘ë³µ í‚¤ê°€ ìˆìŠµë‹ˆë‹¤. (ì¤‘ë³µ: {len(noisy_files) - len(noisy_dict)}ê°œ)")
                
                # ì›ë³¸ ë°ì´í„°ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ë…¸ì´ì¦ˆ ë°ì´í„° ì°¾ê¸°
                matched_count = 0
                unmatched_samples = []
                matched_samples = []
                
                for folder_name, clean_files in clean_folders.items():
                    for clean_file in clean_files:
                        # ì›ë³¸ íŒŒì¼ëª…: aachen_000000_000019_leftImg8bit.png
                        clean_stem = clean_file.stem  # aachen_000000_000019_leftImg8bit
                        
                        # ë…¸ì´ì¦ˆ ë°ì´í„°ì—ì„œ ë§¤ì¹­
                        if clean_stem in noisy_dict:
                            pairs.append((noisy_dict[clean_stem], clean_file))
                            matched_count += 1
                            # ë§¤ì¹­ ì„±ê³µ ìƒ˜í”Œ ìˆ˜ì§‘ (ì²˜ìŒ 3ê°œë§Œ)
                            if len(matched_samples) < 3:
                                matched_samples.append((clean_file.name, clean_stem))
                        else:
                            # ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ ìˆ˜ì§‘ (ì²˜ìŒ 10ê°œ)
                            if len(unmatched_samples) < 10:
                                unmatched_samples.append((clean_file.name, clean_stem))
                
                # ë§¤ì¹­ ì„±ê³µ ìƒ˜í”Œ ì¶œë ¥
                if matched_samples:
                    print(f"  âœ… ë§¤ì¹­ ì„±ê³µ ìƒ˜í”Œ (ì²˜ìŒ {len(matched_samples)}ê°œ):")
                    for clean_name, clean_stem in matched_samples:
                        print(f"     - {clean_name[:70]}... -> {clean_stem}")
                
                # ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ ì¶œë ¥
                if unmatched_samples:
                    print(f"  âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ (ì²˜ìŒ {len(unmatched_samples)}ê°œ):")
                    for clean_name, clean_stem in unmatched_samples[:10]:
                        # ë…¸ì´ì¦ˆ ë°ì´í„°ì˜ í‚¤ ìƒ˜í”Œë„ ì¶œë ¥
                        noisy_keys_sample = list(noisy_dict.keys())[:5]
                        print(f"     - ì›ë³¸: {clean_name[:50]}... (stem: {clean_stem})")
                        print(f"       ë…¸ì´ì¦ˆ í‚¤ ìƒ˜í”Œ: {noisy_keys_sample}")
                
                if matched_count > 0:
                    total_clean = sum(len(files) for files in clean_folders.values())
                    unmatched_clean_count = total_clean - matched_count
                    print(f'  âœ… {split_name} (ì›ë³¸ ê¸°ì¤€): {matched_count}ê°œ ë§¤ì¹­ ì„±ê³µ')
                    print(f'     - ë…¸ì´ì¦ˆ íŒŒì¼: {len(noisy_files)}ê°œ')
                    print(f'     - ì›ë³¸ íŒŒì¼: {total_clean}ê°œ')
                    print(f'     - ë§¤ì¹­ëœ ìŒ: {matched_count}ê°œ')
                    if unmatched_clean_count > 0:
                        print(f'     - âš ï¸  ë§¤ì¹­ë˜ì§€ ì•Šì€ ì›ë³¸ íŒŒì¼: {unmatched_clean_count}ê°œ (ë…¸ì´ì¦ˆ ë°ì´í„°ì— ì—†ìŒ)')
            else:
                # ë…¸ì´ì¦ˆ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì›ë³¸ ë°ì´í„° ì°¾ê¸° (ê¸°ì¡´ ë°©ì‹)
                # 1ë‹¨ê³„ ë§¤ì¹­: ì •í™•í•œ íŒŒì¼ëª…ë§Œ ë§¤ì¹­
                # ì›ë³¸ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                clean_dict = {}  # ì •í™•í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë§¤ì¹­
                
                for folder_name, clean_files in clean_folders.items():
                    for clean_file in clean_files:
                        # ì›ë³¸ íŒŒì¼ëª…: aachen_000000_000019_leftImg8bit.png
                        clean_stem = clean_file.stem  # aachen_000000_000019_leftImg8bit
                        
                        # ì •í™•í•œ í‚¤ (ì „ì²´ stem)
                        clean_dict[clean_stem] = clean_file
                
                # ë…¸ì´ì¦ˆ ë°ì´í„°ë¥¼ ì •í™•í•œ íŒŒì¼ëª…ìœ¼ë¡œë§Œ ë§¤ì¹­
                matched_count = 0
                unmatched_samples = []
                
                for noisy_file in noisy_files:
                    noisy_stem = noisy_file.stem
                    # ë…¸ì´ì¦ˆ íŒŒì¼ëª…: aachen_000004_000019_leftImg8bit_rain_alpha_0.02_...
                    # _rain ì´í›„ ëª¨ë“  ë¶€ë¶„ ì œê±°
                    if '_rain' in noisy_stem:
                        noisy_key = noisy_stem.split('_rain')[0]  # aachen_000004_000019_leftImg8bit
                    else:
                        noisy_key = noisy_stem
                    
                    # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                    if noisy_key in clean_dict:
                        pairs.append((noisy_file, clean_dict[noisy_key]))
                        matched_count += 1
                    else:
                        # ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ ìˆ˜ì§‘ (ì²˜ìŒ 3ê°œë§Œ)
                        if len(unmatched_samples) < 3:
                            unmatched_samples.append((noisy_file.name, noisy_key))
                
                # ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ ì¶œë ¥
                if unmatched_samples:
                    print(f"  âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨ ìƒ˜í”Œ (ì²˜ìŒ {len(unmatched_samples)}ê°œ):")
                    # ì›ë³¸ ë°ì´í„°ì˜ í‚¤ ìƒ˜í”Œë„ ì¶œë ¥
                    clean_keys_sample = list(clean_dict.keys())[:5]
                    print(f"     ì›ë³¸ í‚¤ ìƒ˜í”Œ: {clean_keys_sample}")
                    for noisy_name, noisy_key in unmatched_samples[:5]:
                        print(f"     - ë…¸ì´ì¦ˆ: {noisy_name[:60]}...")
                        print(f"       ì¶”ì¶œëœ í‚¤: {noisy_key}")
                        # ìœ ì‚¬í•œ í‚¤ ì°¾ê¸°
                        similar_keys = [k for k in clean_keys_sample if noisy_key.split('_')[0] in k or k.split('_')[0] in noisy_key]
                        if similar_keys:
                            print(f"       ìœ ì‚¬í•œ ì›ë³¸ í‚¤: {similar_keys[:3]}")
                
                if matched_count > 0:
                    total_clean = sum(len(files) for files in clean_folders.values())
                    unmatched_noisy_count = len(noisy_files) - matched_count
                    print(f'  âœ… {split_name} (ë…¸ì´ì¦ˆ ê¸°ì¤€): {matched_count}ê°œ ë§¤ì¹­ ì„±ê³µ')
                    print(f'     - ë…¸ì´ì¦ˆ íŒŒì¼: {len(noisy_files)}ê°œ')
                    print(f'     - ì›ë³¸ íŒŒì¼: {total_clean}ê°œ')
                    print(f'     - ë§¤ì¹­ëœ ìŒ: {matched_count}ê°œ')
                    if unmatched_noisy_count > 0:
                        print(f'     - âš ï¸  ë§¤ì¹­ë˜ì§€ ì•Šì€ ë…¸ì´ì¦ˆ íŒŒì¼: {unmatched_noisy_count}ê°œ (ì›ë³¸ ë°ì´í„°ì— ì—†ìŒ)')
                else:
                    # ë§¤ì¹­ì´ í•˜ë‚˜ë„ ì•ˆ ë˜ë©´ ë” ìì„¸í•œ ì •ë³´ ì¶œë ¥
                    total_clean = sum(len(files) for files in clean_folders.values())
                    print(f'  âŒ {split_name} (ë…¸ì´ì¦ˆ ê¸°ì¤€): ë§¤ì¹­ ì‹¤íŒ¨')
                    print(f'     - ë…¸ì´ì¦ˆ íŒŒì¼: {len(noisy_files)}ê°œ')
                    print(f'     - ì›ë³¸ íŒŒì¼: {total_clean}ê°œ')
                    if len(noisy_files) > 0 and total_clean > 0:
                        # ë…¸ì´ì¦ˆ í‚¤ ìƒ˜í”Œ
                        noisy_keys_sample = []
                        for nf in noisy_files[:5]:
                            ns = nf.stem
                            if '_rain' in ns:
                                nk = ns.split('_rain')[0]
                            else:
                                nk = ns
                            noisy_keys_sample.append(nk)
                        print(f'     - ë…¸ì´ì¦ˆ í‚¤ ìƒ˜í”Œ: {noisy_keys_sample}')
                        print(f'     - ì›ë³¸ í‚¤ ìƒ˜í”Œ: {list(clean_dict.keys())[:5]}')
        
        return pairs
    
    def __len__(self):
        return len(self.pairs)
    
    def __getitem__(self, idx):
        noisy_path, clean_path = self.pairs[idx]
        
        # Noisy ì´ë¯¸ì§€ ë¡œë“œ
        noisy_img = cv2.imread(str(noisy_path))
        if noisy_img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {noisy_path}")
        
        # Inference ì „ìš© ëª¨ë“œë©´ clean ì´ë¯¸ì§€ ì—†ì´ ë°˜í™˜
        if self.inference_only or clean_path is None:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if noisy_img.shape[:2] != (512, 512):
                noisy_img = cv2.resize(noisy_img, (512, 512), interpolation=cv2.INTER_LINEAR)
            noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)
            noisy_img = noisy_img.astype(np.float32) / 255.0
            noisy_img = torch.from_numpy(noisy_img).permute(2, 0, 1)
            
            if self.transform:
                noisy_img = self.transform(noisy_img)
            
            return noisy_img, None  # cleanì€ None ë°˜í™˜
        
        # ê¸°ì¡´ ì½”ë“œ (clean ì´ë¯¸ì§€ë„ ë¡œë“œ)
        clean_img = cv2.imread(str(clean_path))
        if clean_img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {clean_path}")
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ ë° ë¦¬ì‚¬ì´ì¦ˆ (512x512ë¡œ í†µì¼)
        if noisy_img.shape[:2] != (512, 512):
            noisy_img = cv2.resize(noisy_img, (512, 512), interpolation=cv2.INTER_LINEAR)
        if clean_img.shape[:2] != (512, 512):
            clean_img = cv2.resize(clean_img, (512, 512), interpolation=cv2.INTER_LINEAR)
        
        # BGR to RGB
        noisy_img = cv2.cvtColor(noisy_img, cv2.COLOR_BGR2RGB)
        clean_img = cv2.cvtColor(clean_img, cv2.COLOR_BGR2RGB)
        
        # 0-255 -> 0-1ë¡œ ì •ê·œí™”
        noisy_img = noisy_img.astype(np.float32) / 255.0
        clean_img = clean_img.astype(np.float32) / 255.0
        
        # HWC -> CHW ë³€í™˜
        noisy_img = torch.from_numpy(noisy_img).permute(2, 0, 1)
        clean_img = torch.from_numpy(clean_img).permute(2, 0, 1)
        
        if self.transform:
            noisy_img = self.transform(noisy_img)
            clean_img = self.transform(clean_img)
        
        return noisy_img, clean_img


class EarlyStopping:
    """
    Early Stopping êµ¬í˜„
    """
    def __init__(self, patience=10, min_delta=0, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_loss = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.save_checkpoint(model)
        elif val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
            self.save_checkpoint(model)
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False
    
    def save_checkpoint(self, model):
        self.best_weights = model.state_dict().copy()


def calculate_psnr(img1, img2):
    """PSNR ê³„ì‚°"""
    img1 = img1.cpu().numpy()
    img2 = img2.cpu().numpy()
    return psnr(img1, img2, data_range=1.0)


def calculate_ssim(img1, img2):
    """SSIM ê³„ì‚° (ìµœì í™” ë²„ì „)"""
    img1 = img1.cpu().numpy()
    img2 = img2.cpu().numpy()
    
    # win_sizeë¥¼ í•œ ë²ˆë§Œ ê³„ì‚° (512x512 ì´ë¯¸ì§€ì´ë¯€ë¡œ 11 ì‚¬ìš©)
    win_size = 11  # 512x512 ì´ë¯¸ì§€ì— ì í•©
    
    def compute_ssim_single(img1_single, img2_single):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ìŒì— ëŒ€í•œ SSIM ê³„ì‚°"""
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (H, W, C)
        h, w = img1_single.shape[:2]
        
        # win_sizeë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        actual_win_size = min(win_size, min(h, w))
        if actual_win_size % 2 == 0:
            actual_win_size -= 1
        actual_win_size = max(3, actual_win_size)
        
        # ìµœì‹  API ì‚¬ìš© (channel_axis)
        try:
            # scikit-image 0.19+ ë²„ì „
            if len(img1_single.shape) == 3 and img1_single.shape[2] == 3:
                return ssim(img1_single, img2_single, 
                           win_size=actual_win_size,
                           channel_axis=2,
                           data_range=1.0)
            else:
                return ssim(img1_single, img2_single,
                           win_size=actual_win_size,
                           data_range=1.0)
        except TypeError:
            # êµ¬ë²„ì „ í˜¸í™˜ (multichannel ì‚¬ìš©)
            if len(img1_single.shape) == 3 and img1_single.shape[2] == 3:
                return ssim(img1_single, img2_single,
                           win_size=actual_win_size,
                           multichannel=True,
                           data_range=1.0)
            else:
                return ssim(img1_single, img2_single,
                           win_size=actual_win_size,
                           data_range=1.0)
    
    if len(img1.shape) == 4:  # batch dimension
        ssim_values = []
        for i in range(img1.shape[0]):
            img1_transposed = img1[i].transpose(1, 2, 0)
            img2_transposed = img2[i].transpose(1, 2, 0)
            ssim_val = compute_ssim_single(img1_transposed, img2_transposed)
            ssim_values.append(ssim_val)
        return np.mean(ssim_values)
    else:
        img1_transposed = img1.transpose(1, 2, 0)
        img2_transposed = img2.transpose(1, 2, 0)
        return compute_ssim_single(img1_transposed, img2_transposed)


def train_model(model, train_loader, val_loader, num_epochs=10, 
                device='cuda', lr=1e-4, checkpoint_dir='checkpoints',
                start_epoch=0, resume_checkpoint=None, l1_weight=1.0, ssim_weight=1.0, gradient_weight=0.5):
    """
    ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
    
    Args:
        l1_weight: L1 Loss ê°€ì¤‘ì¹˜ (default: 1.0)
        ssim_weight: SSIM Loss ê°€ì¤‘ì¹˜ (default: 1.0)
        gradient_weight: Gradient Loss ê°€ì¤‘ì¹˜ (default: 0.5)
    """
    # ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    # ì†ì‹¤ í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì„¤ì • (ê°€ì¤‘ì¹˜ íŠœë‹ ê°€ëŠ¥)
    criterion = CombinedLoss(l1_weight=l1_weight, ssim_weight=ssim_weight, gradient_weight=gradient_weight)
    print(f"Loss ê°€ì¤‘ì¹˜: L1={l1_weight:.2f}, SSIM={ssim_weight:.2f}, Gradient={gradient_weight:.2f}")
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    # Mixed Precision Training (ì•ˆì •ì ì¸ ì„¤ì •ìœ¼ë¡œ í™œì„±í™”)
    use_amp = device.type == 'cuda'  # GPUì—ì„œë§Œ ì‚¬ìš©
    # ë” ë³´ìˆ˜ì ì¸ loss scalingìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ
    scaler = torch.cuda.amp.GradScaler(init_scale=2.**10, growth_factor=2.0, backoff_factor=0.5) if use_amp else None
    
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
    if resume_checkpoint and os.path.exists(resume_checkpoint):
        checkpoint = torch.load(resume_checkpoint, map_location=device)
        if 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            # Optimizer stateë¥¼ GPUë¡œ ì´ë™
            if device.type == 'cuda':
                for state in optimizer.state.values():
                    for k, v in state.items():
                        if isinstance(v, torch.Tensor):
                            state[k] = v.to(device)
            print(f'âœ… Optimizer ìƒíƒœ ë³µì› ì™„ë£Œ')
        if 'scaler_state_dict' in checkpoint and scaler is not None:
            scaler.load_state_dict(checkpoint['scaler_state_dict'])
            print(f'âœ… Scaler ìƒíƒœ ë³µì› ì™„ë£Œ')
        best_val_loss = checkpoint.get('val_loss', float('inf'))
        print(f'âœ… Best Val Loss ë³µì›: {best_val_loss:.4f}')
    else:
        best_val_loss = float('inf')
    
    if use_amp:
        print(f'âœ… Mixed Precision Training í™œì„±í™” (ì•ˆì •ì ì¸ ì„¤ì •)')
        print(f'   - Loss scaling: init_scale=2^10 (ë³´ìˆ˜ì  ì„¤ì •)')
    else:
        print(f'âš ï¸  Mixed Precision Training ë¹„í™œì„±í™” (CPU ëª¨ë“œ)')
    
    # Early Stopping (patience ì¤„ì—¬ì„œ ë” ë¹¨ë¦¬ ì¤‘ë‹¨)
    early_stopping = EarlyStopping(patience=5, min_delta=0.001)
    
    # í•™ìŠµ ê¸°ë¡
    train_losses = []
    val_losses = []
    val_psnrs = []
    val_ssims = []
    
    model.to(device)
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if device.type == 'cuda':
        torch.cuda.empty_cache()  # ìºì‹œ ì •ë¦¬
        torch.cuda.synchronize()  # ë™ê¸°í™”
        print(f'\nGPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ!')
        print(f'GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì •ë¦¬ í›„):')
        print(f'  í• ë‹¹ë¨: {torch.cuda.memory_allocated(device) / 1024**3:.2f} GB')
        print(f'  ì˜ˆì•½ë¨: {torch.cuda.memory_reserved(device) / 1024**3:.2f} GB')
        print()
    
    for epoch in range(start_epoch, num_epochs):
        # Training
        model.train()
        train_loss = 0.0
        
        print(f'\n=== Epoch [{epoch+1}/{num_epochs}] ===')
        print('Training ì‹œì‘...')
        
        # Epoch ì‹œì‘ ì‹œê°„ ê¸°ë¡
        import time
        epoch_start_time = time.time()
        
        # ì²« epochì—ì„œ device í™•ì¸
        if epoch == 0:
            print(f'ğŸ” Device í™•ì¸:')
            print(f'   - device ë³€ìˆ˜: {device}')
            print(f'   - device.type: {device.type}')
            print(f'   - torch.cuda.is_available(): {torch.cuda.is_available()}')
            print(f'   - ëª¨ë¸ì´ GPUì— ìˆëŠ”ì§€: {next(model.parameters()).is_cuda}')
            print(f'   - ëª¨ë¸ device: {next(model.parameters()).device}')
            if device.type == 'cuda':
                print(f'   - í˜„ì¬ CUDA device: {torch.cuda.current_device()}')
                print(f'   - GPU ì´ë¦„: {torch.cuda.get_device_name(device)}')
            print()
        
        for batch_idx, (noisy, clean) in enumerate(train_loader):
            # ë°°ì¹˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            batch_start_time = time.time()
            
            # ì²« ë°°ì¹˜ ë¡œë”© ì™„ë£Œ ì•Œë¦¼
            if batch_idx == 0:
                data_load_time = time.time() - batch_start_time
                print(f'ì²« ë°°ì¹˜ ë¡œë”© ì™„ë£Œ! Shape: {noisy.shape}')
                print(f'â±ï¸  ë°ì´í„° ë¡œë”© ì‹œê°„: {data_load_time:.3f}ì´ˆ')
                print(f'   - ë¡œë”© í›„: noisy.is_cuda={noisy.is_cuda}, device={noisy.device}')
            
            # ë°ì´í„° ì „ì†¡ ì‹œê°„ ì¸¡ì •
            data_transfer_start = time.time()
            noisy = noisy.to(device, non_blocking=True)
            clean = clean.to(device, non_blocking=True)
            if device.type == 'cuda':
                torch.cuda.synchronize()
            data_transfer_time = time.time() - data_transfer_start
            
            # ì²« ë°°ì¹˜ì—ì„œ GPU ì „ì†¡ í™•ì¸
            if batch_idx == 0:
                print(f'   - GPU ì „ì†¡ í›„: noisy.is_cuda={noisy.is_cuda}, device={noisy.device}')
                print(f'   - ëª¨ë¸ device: {next(model.parameters()).device}')
                if not noisy.is_cuda and device.type == 'cuda':
                    print(f'   âš ï¸  ê²½ê³ : GPUë¡œ ì „ì†¡ ì‹¤íŒ¨! CPUë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.')
                    print(f'   âš ï¸  device={device}ì¸ë° ë°ì´í„°ê°€ CPUì— ìˆìŠµë‹ˆë‹¤.')
                    print(f'   âš ï¸  CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.')
                elif noisy.is_cuda:
                    print(f'   âœ… GPU ì‚¬ìš© í™•ì¸ë¨!')
                print()
            
            # Forward pass ì‹œê°„ ì¸¡ì • (Mixed Precision ì‚¬ìš©)
            forward_start = time.time()
            optimizer.zero_grad()
            
            if scaler is not None:
                # Mixed Precision forward pass
                with torch.amp.autocast('cuda'):
                    output = model(noisy)
                    loss = criterion(output, clean)
            else:
                output = model(noisy)
                loss = criterion(output, clean)
            
            # ë™ê¸°í™”ëŠ” ìµœì†Œí™” (ì‹œê°„ ì¸¡ì •ì„ ìœ„í•´ ì²« ë°°ì¹˜ì—ì„œë§Œ)
            if device.type == 'cuda' and batch_idx == 0:
                torch.cuda.synchronize()
            forward_time = time.time() - forward_start
            
            # Backward pass ì‹œê°„ ì¸¡ì • (Mixed Precision ì‚¬ìš©)
            backward_start = time.time()
            
            if scaler is not None:
                # Mixed Precision backward pass
                scaler.scale(loss).backward()
                # Gradient clippingì€ 20ë°°ì¹˜ë§ˆë‹¤ë§Œ ìˆ˜í–‰ (ì†ë„ ê°œì„ )
                if (batch_idx + 1) % 20 == 0:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                # Gradient Clippingì€ 20ë°°ì¹˜ë§ˆë‹¤ë§Œ ìˆ˜í–‰ (ì†ë„ ê°œì„ )
                if (batch_idx + 1) % 20 == 0:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)
                optimizer.step()
            
            # ë™ê¸°í™”ëŠ” ì™„ì „íˆ ì œê±° (ì‹œê°„ ì¸¡ì •ìš©ì´ë¯€ë¡œ í•™ìŠµì—ëŠ” ì˜í–¥ ì—†ìŒ)
            # if device.type == 'cuda' and (batch_idx + 1) % 10 == 0:
            #     torch.cuda.synchronize()
            backward_time = time.time() - backward_start
            
            train_loss += loss.item()
            
            # ì´ ë°°ì¹˜ ì²˜ë¦¬ ì‹œê°„
            total_batch_time = time.time() - batch_start_time
            
            # 2ë°°ì¹˜ë§ˆë‹¤ ì§„í–‰ ìƒí™© ë° ì‹œê°„ ë¶„ì„ ì¶œë ¥
            if (batch_idx + 1) % 2 == 0:
                avg_loss_so_far = train_loss / (batch_idx + 1)
                elapsed_since_epoch = time.time() - epoch_start_time
                avg_time_per_batch = elapsed_since_epoch / (batch_idx + 1)
                estimated_remaining = avg_time_per_batch * (len(train_loader) - (batch_idx + 1))
                
                print(f'  Progress: [{batch_idx+1}/{len(train_loader)}] batches, Avg Loss: {avg_loss_so_far:.4f}')
                print(f'  â±ï¸  ì‹œê°„ ë¶„ì„:')
                print(f'     - ë°°ì¹˜ë‹¹ í‰ê· : {avg_time_per_batch:.2f}ì´ˆ')
                print(f'     - ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining/60:.1f}ë¶„')
                if batch_idx == 1:  # ì²« 2ë°°ì¹˜ì—ì„œë§Œ ìƒì„¸ ì •ë³´
                    print(f'     - ë°ì´í„° ì „ì†¡: {data_transfer_time:.3f}ì´ˆ')
                    print(f'     - Forward pass: {forward_time:.3f}ì´ˆ')
                    print(f'     - Backward pass: {backward_time:.3f}ì´ˆ')
                    print(f'     - ì´ ë°°ì¹˜ ì‹œê°„: {total_batch_time:.3f}ì´ˆ')
        
        train_loss /= len(train_loader)
        train_losses.append(train_loss)
        
        print(f'Training ì™„ë£Œ! Train Loss: {train_loss:.4f}')
        print('Validation ì‹œì‘...')
        
        # Validation
        model.eval()
        val_loss = 0.0
        val_psnr_sum = 0.0
        val_ssim_sum = 0.0
        
        with torch.no_grad():
            for val_batch_idx, (noisy, clean) in enumerate(val_loader):
                noisy = noisy.to(device, non_blocking=True)
                clean = clean.to(device, non_blocking=True)
                
                if scaler is not None:
                    # Mixed Precision forward pass (validation)
                    with torch.amp.autocast('cuda'):
                        output = model(noisy)
                        loss = criterion(output, clean)
                else:
                    output = model(noisy)
                    loss = criterion(output, clean)
                
                val_loss += loss.item()
                
                # PSNR, SSIM ê³„ì‚°
                val_psnr_sum += calculate_psnr(output, clean)
                val_ssim_sum += calculate_ssim(output, clean)
                
                # Validation ì§„í–‰ ìƒí™© ì¶œë ¥ (5ë°°ì¹˜ë§ˆë‹¤)
                if (val_batch_idx + 1) % 5 == 0:
                    print(f'  Validation Progress: [{val_batch_idx+1}/{len(val_loader)}] batches')
        
        val_loss /= len(val_loader)
        val_psnr = val_psnr_sum / len(val_loader)
        val_ssim = val_ssim_sum / len(val_loader)
        
        val_losses.append(val_loss)
        val_psnrs.append(val_psnr)
        val_ssims.append(val_ssim)
        
        print(f'Validation ì™„ë£Œ!')
        print(f'Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')
        print(f'Val PSNR: {val_psnr:.4f}, Val SSIM: {val_ssim:.4f}')
        
        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥ (ë§¤ epochë§ˆë‹¤)
        if device.type == 'cuda':
            allocated = torch.cuda.memory_allocated(device) / 1024**3
            reserved = torch.cuda.memory_reserved(device) / 1024**3
            print(f'GPU Memory: {allocated:.2f} GB / {reserved:.2f} GB')
        
        # Checkpoint ì €ì¥ (best validation loss)
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            checkpoint_data = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'val_psnr': val_psnr,
                'val_ssim': val_ssim,
            }
            if scaler is not None:
                checkpoint_data['scaler_state_dict'] = scaler.state_dict()
            # ê²½ë¡œ ì •ê·œí™” ë° ë””ë ‰í† ë¦¬ í™•ì¸
            checkpoint_path = Path(checkpoint_dir) / 'best_model.pth'
            checkpoint_path.parent.mkdir(parents=True, exist_ok=True)
            torch.save(checkpoint_data, str(checkpoint_path))
            print(f'Checkpoint saved! (Val Loss: {val_loss:.4f})')
        
        # Early Stopping ì²´í¬
        if early_stopping(val_loss, model):
            print(f'Early stopping at epoch {epoch+1}')
            break
        
        print('-' * 50)
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_psnrs': val_psnrs,
        'val_ssims': val_ssims
    }


def evaluate_model(model, test_loader, device='cuda'):
    """
    ëª¨ë¸ í‰ê°€ í•¨ìˆ˜
    """
    model.eval()
    test_psnr_sum = 0.0
    test_ssim_sum = 0.0
    
    with torch.no_grad():
        for noisy, clean in test_loader:
            noisy = noisy.to(device)
            clean = clean.to(device)
            
            output = model(noisy)
            
            test_psnr_sum += calculate_psnr(output, clean)
            test_ssim_sum += calculate_ssim(output, clean)
    
    avg_psnr = test_psnr_sum / len(test_loader)
    avg_ssim = test_ssim_sum / len(test_loader)
    
    print(f'Test PSNR: {avg_psnr:.4f}')
    print(f'Test SSIM: {avg_ssim:.4f}')
    
    return avg_psnr, avg_ssim


if __name__ == '__main__':
    # ì˜ˆì œ ì‚¬ìš©ë²•
    print("CNN ëª¨ë¸ ì •ì˜ ì™„ë£Œ!")
    print("ì‚¬ìš© ë°©ë²•:")
    print("1. ë°ì´í„°ì…‹ ì¤€ë¹„: noisy_dir, clean_dir ì„¤ì •")
    print("2. DataLoader ìƒì„±")
    print("3. train_model() í•¨ìˆ˜ë¡œ í•™ìŠµ")
    print("4. evaluate_model() í•¨ìˆ˜ë¡œ í‰ê°€")
    
    # ëª¨ë¸ ìƒì„± ì˜ˆì œ
    model = CNNModel(in_channels=3, out_channels=3)
    print(f"\nëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

