"""
Streamlit ì•±: ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±° ì‹œê°í™”
lastcheckpointsì— ì €ì¥ëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""
import streamlit as st
import torch
import cv2
import numpy as np
from pathlib import Path
import time
from PIL import Image
import io
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (second_checkpoints ì ‘ê·¼ìš©)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(Path(__file__).parent))

# ëª¨ë¸ import (ê²½ë¡œì— ë”°ë¼ ìë™ìœ¼ë¡œ ì°¾ê¸°)
try:
    from team.cnn_model import CNNModel
    from team.unet_model import UNet
except ImportError:
    # team í´ë”ì—ì„œ ì§ì ‘ ì‹¤í–‰í•˜ëŠ” ê²½ìš°
    from cnn_model import CNNModel
    from unet_model import UNet

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        font-size: 1.2rem;
        height: 3rem;
    }
</style>
""", unsafe_allow_html=True)

# ì œëª©
st.markdown('<p class="main-header">âœ¨ ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ë…¸ì´ì¦ˆ ì œê±° ì‹œì—°</p>', unsafe_allow_html=True)
st.markdown("---")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì • (lastcheckpoints ì‚¬ìš©)
# team/lastcheckpoints í´ë”ì— ìˆëŠ” ëª¨ë¸ ì‚¬ìš©
team_dir = Path(__file__).parent
lastcheckpoints_dir = team_dir / "lastcheckpoints"
cnn_model_path = lastcheckpoints_dir / "cnn" / "best_model.pth"
unet_model_path = lastcheckpoints_dir / "unet" / "best_model.pth"

cnn_exists = cnn_model_path.exists()
unet_exists = unet_model_path.exists()

# ëª¨ë¸ ì •ë³´ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•Šê²Œ)

models_ready = cnn_exists and unet_exists

# ë””ë°”ì´ìŠ¤ ì„ íƒ (ì‚¬ì´ë“œë°”ì— í‘œì‹œí•˜ì§€ ì•ŠìŒ, ìë™ìœ¼ë¡œ ì„¤ì •)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ìºì‹±)
@st.cache_resource
def load_model(model_type, model_path, device):
    """ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤"""
    try:
        if model_type == "CNN":
            model = CNNModel(in_channels=3, out_channels=3)
        else:
            model = UNet(in_channels=3, out_channels=3)
        
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()
        
        # ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
        info = {
            'epoch': checkpoint.get('epoch', 'N/A'),
            'val_loss': checkpoint.get('val_loss', 'N/A'),
            'val_psnr': checkpoint.get('val_psnr', 'N/A'),
            'val_ssim': checkpoint.get('val_ssim', 'N/A')
        }
        
        return model, info
    except FileNotFoundError:
        st.error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None, None
    except Exception as e:
        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(image, target_size=(512, 512)):
    """ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    if isinstance(image, Image.Image):
        img_array = np.array(image)
    else:
        img_array = image
    
    # RGBë¡œ ë³€í™˜
    if len(img_array.shape) == 2:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
    elif img_array.shape[2] == 4:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
    
    # ì›ë³¸ í¬ê¸° ì €ì¥ (ë‚˜ì¤‘ì— ë³µì›ìš©)
    original_size = img_array.shape[:2]
    
    # ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (512x512)
    if img_array.shape[:2] != target_size:
        img_array = cv2.resize(img_array, target_size, interpolation=cv2.INTER_LINEAR)
    
    # [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
    img_array = img_array.astype(np.float32) / 255.0
    
    # í…ì„œë¡œ ë³€í™˜: (H, W, C) -> (1, C, H, W)
    img_tensor = torch.from_numpy(img_array).permute(2, 0, 1).unsqueeze(0)
    
    return img_tensor, original_size

# ë…¸ì´ì¦ˆ ì œê±° í•¨ìˆ˜
def denoise_image(model, image_tensor, device, original_size=None):
    """ì´ë¯¸ì§€ì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤"""
    model.eval()
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        output = model(image_tensor)
        output = output.squeeze(0).cpu().numpy()
        output = output.transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)
        output = np.clip(output, 0, 1)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì› (í•„ìš”í•œ ê²½ìš°)
        if original_size is not None and output.shape[:2] != original_size:
            output = cv2.resize(output, (original_size[1], original_size[0]), interpolation=cv2.INTER_LINEAR)
    
    return output

# ë©”ì¸ ì»¨í…ì¸ 
st.subheader("ğŸ“¤ ì…ë ¥ ì´ë¯¸ì§€")

# ëª¨ë¸ì´ ì—†ì„ ë•Œ ì•ˆë‚´ (ìµœì†Œí™” - Hugging Faceê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬)
if not models_ready:
    st.info("â³ ëª¨ë¸ì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
uploaded_file = st.file_uploader(
    "ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=['png', 'jpg', 'jpeg'],
    help="JPG, PNG í˜•ì‹ì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
    disabled=not models_ready  # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì—…ë¡œë“œ ë¹„í™œì„±í™”
)

# ì´ë¯¸ì§€ í‘œì‹œ
input_image = None
if uploaded_file is not None:
    input_image = Image.open(uploaded_file)
    st.image(input_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
    
    # ì´ë¯¸ì§€ ì •ë³´
    st.info(f"ğŸ“ í¬ê¸°: {input_image.size[0]} Ã— {input_image.size[1]} pixels")
    
    # ë…¸ì´ì¦ˆ ì œê±° ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ CNN & U-Net ë™ì‹œ ì‹¤í–‰", type="primary", use_container_width=True):
        if not models_ready:
            st.error("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            # ë‘ ëª¨ë¸ ëª¨ë‘ ë¡œë“œ
            with st.spinner("ëª¨ë¸ ë¡œë”© ì¤‘..."):
                cnn_model, cnn_info = load_model("CNN", cnn_model_path, device)
                unet_model, unet_info = load_model("U-Net", unet_model_path, device)
            
            if cnn_model is None or unet_model is None:
                st.error("ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í•œ ë²ˆë§Œ)
                image_tensor, original_size = preprocess_image(input_image)
                
                # CNN ì²˜ë¦¬
                with st.spinner("CNN ëª¨ë¸ ì²˜ë¦¬ ì¤‘..."):
                    cnn_start = time.time()
                    cnn_result = denoise_image(cnn_model, image_tensor, device, original_size)
                    cnn_time = time.time() - cnn_start
                
                # U-Net ì²˜ë¦¬
                with st.spinner("U-Net ëª¨ë¸ ì²˜ë¦¬ ì¤‘..."):
                    unet_start = time.time()
                    unet_result = denoise_image(unet_model, image_tensor, device, original_size)
                    unet_time = time.time() - unet_start
                
                # ê²°ê³¼ë¥¼ 3ì—´ë¡œ í‘œì‹œ
                st.markdown("---")
                st.subheader("âœ¨ ë…¸ì´ì¦ˆ ì œê±° ê²°ê³¼ ë¹„êµ")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.image(input_image, caption="ì›ë³¸ (ë…¸ì´ì¦ˆ ìˆìŒ)", use_container_width=True)
                
                with col2:
                    st.image(cnn_result, caption="CNN ê²°ê³¼", use_container_width=True)
                    st.metric("ì²˜ë¦¬ ì‹œê°„", f"{cnn_time*1000:.1f} ms")
                    
                    # CNN ë‹¤ìš´ë¡œë“œ
                    cnn_pil = Image.fromarray((cnn_result * 255).astype(np.uint8))
                    cnn_buf = io.BytesIO()
                    cnn_pil.save(cnn_buf, format='PNG')
                    cnn_buf.seek(0)
                    st.download_button(
                        label="ğŸ“¥ CNN ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        data=cnn_buf,
                        file_name=f"denoised_cnn_{int(time.time())}.png",
                        mime="image/png",
                        key="cnn_download"
                    )
                
                with col3:
                    st.image(unet_result, caption="U-Net ê²°ê³¼", use_container_width=True)
                    st.metric("ì²˜ë¦¬ ì‹œê°„", f"{unet_time*1000:.1f} ms")
                    
                    # U-Net ë‹¤ìš´ë¡œë“œ
                    unet_pil = Image.fromarray((unet_result * 255).astype(np.uint8))
                    unet_buf = io.BytesIO()
                    unet_pil.save(unet_buf, format='PNG')
                    unet_buf.seek(0)
                    st.download_button(
                        label="ğŸ“¥ U-Net ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                        data=unet_buf,
                        file_name=f"denoised_unet_{int(time.time())}.png",
                        mime="image/png",
                        key="unet_download"
                    )
                
                # ëª¨ë¸ ì •ë³´ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
                
                # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ ì €ì¥
                st.session_state['cnn_result'] = cnn_result
                st.session_state['unet_result'] = unet_result
                st.session_state['input_image'] = input_image
else:
    st.info("ğŸ‘† ìœ„ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")

# ì¶”ê°€ ë¹„êµ ë·° (ê²°ê³¼ê°€ ìˆì„ ë•Œ)
if 'cnn_result' in st.session_state and 'unet_result' in st.session_state and 'input_image' in st.session_state:
    st.markdown("---")
    st.subheader("ğŸ“Š ìƒì„¸ ë¹„êµ")
    
    # ìŠ¬ë¼ì´ë”ë¡œ í™•ëŒ€/ì¶•ì†Œ ê°€ëŠ¥í•œ ë¹„êµ ë·°
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.image(st.session_state['input_image'], caption="ì›ë³¸", use_container_width=True)
    
    with col2:
        st.image(st.session_state['cnn_result'], caption="CNN ê²°ê³¼", use_container_width=True)
    
    with col3:
        st.image(st.session_state['unet_result'], caption="U-Net ê²°ê³¼", use_container_width=True)

# í‘¸í„°
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray; padding: 1rem;'>ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±° ì‹œê°í™” ë„êµ¬ | ë”¥ëŸ¬ë‹ ê¸°ë°˜</div>",
    unsafe_allow_html=True
)

